# FutureMakers
The MIT FutureMakers + SureStart Applied Deep Learning Program is a 6-week AI learning program, developed with collaboration with [SureStart](https://mysurestart.com/) and the [MIT RAISE (Responsible AI for Social Empowerment and Education) Initiative](https://raise.mit.edu/).

### July 2021
| Sun | Mon | Tue | Wed | Thu | Fri | Sat |
|-----|-----|-----|-----|-----|-----|-----|
| 04  | 05  | 06  | 07  | 08  | 09  | 10  |
| 11  | 12  | 13  | 14  | 15  | 16  | 17  |
| 18  | 19  | 20  | 21  | 22  | 23  | 24  |
| 25  | 26  | 27  | 28  | 29  | 30  | 31  |


## Day 1 (July 6, 2021):
Today, I refreshed myself on my Python skills and reviewed the rest of the Ramp Up document to get ready for the future.

Reflection Activity: Reflect on what you hope to learn in this program. I hope to master my skills on Python and using GitHub (!), along with the core of AI, Machine Learning Model Development and Neural Networks. There is so much to explore, so I am genuinely excited for the next few weeks.

## Day 2 (July 7, 2021):
Today I attended Dr. David Kong's Leadership and Storytelling Workshop, which allowed me to become closer with some of my peers. I also met my team and mentor, Elle, today, and I look forward to working/creating with them soon!

Reflection Activity: Reflect on what you learned in Dr. David Kongâ€™s leadership seminar about yourself, the world, and what are your unique contributions to your community. I learned Dr. Kong's storytelling framework: Challenge, Choice and Outcome, and the importance of zoning in on one major moment to describe your feelings, motivations and dreams for the future. I was surprised by the other scholars' storytelling abilities, and my own! I loved one of my peer's comments: 'everyone has an impactful story to share within them, no matter their age or experience', which I think is incredibly true.

## Day 3 (July 8, 2021):
Today I re-learned the basics of ML and Neural Networks. I also attended a Diversity, Equity and Inclusion Seminar by Salila Yoon, where we learned the importance of inclusion and how to include others in different situations.

Reflection Activity: 1. What is the difference between supervised and unsupervised learning? 2. Describe why the following statement is FALSE: Scikit-Learn has the power to visualize data without a Graphviz, Pandas, or other data analysis libraries. (1) The difference between supervised and unsupervised learning is pretty important to the study of ML. Supervised machine learning is when the program is trained on a set of preset training examples, which allow it to learn, become more accurate and reach a conclusion when given new data. Unsupervised machine learning is when the program is given simply given data and must discover patterns/relationships within that. (2) Scikit-Learn does not have the power to visualize data without Graphviz, Pandas, or other data analysis libraries, because it is solely focused on data modeling. It cannot load, handle, manipulate, visualize or analyze the data. Therefore, it is necessary to use many other libraries for the remaining steps.

## Day 4 (July 9, 2021):
Today I continued working on my first project, the Iris Data Set Project aka my Intro to Scikit-learn, and uploading it to GitHub! I also read through the article on Deep Learning models and neural networks, and actually understood the difference between traditional ML and DL.

Reflection Activity: Think about a real-world problem and see if you can find a dataset that has the characteristics of the data of that problem.

Problem - Tsunamis have always been known to be incredibly dangerous, especially to coastline communities, and can cause thousands of civilans to die. They cause flooding, immense destruction on infrastructure, and disrupt transportation, power, communications, water supply and more.

Dataset - Just with a quick Google Search, I've already found two datasets: https://www.kaggle.com/andrewmvd/tsunami-dataset and https://www.kaggle.com/noaa/seismic-waves. But, I can always dig deeper to find more.

Solution + Algorithm - By predicting the location, magnitude and intensity of a Tsunami, thousands of lives can be saved. A Deep Learning Model could be trained to recognize patterns in previous Tsunamis and predict the next one in real time. I believe we could use Recurrent Neural Networks, or Convolutional Neural Networks, to process text, video and image samples from these datasets.

## Day 5+6 - Weekend (July 10 + 11, 2021)
Over the Weekend, I read the article on Ethics in Machine Learning and took in-depth notes. I hope this is only the beginning of our studies about Ethical CS and AI, as it is an essential part in the discussion of Machine Learning as a whole. After improving the functions of my code, I also re-uploaded my Iris Data Set Project from Friday.

## Day 7 (July 12, 2021)
Today was pretty tough! I read through the two articles/tutorials introducing TensorFlow and Keras, but I had a lot of trouble downloading importing TensorFLow, which required lots of troubleshooting and researching to resolve. Luckily, I got it finished!

Reflection Activity: 1. What are 'Tensors' and what are they used for in Machine Learning? 2. What did you notice about the computations that you ran in the TensorFlow programs/models in the tutorial? (1) Tensors are multidimensional arrays with a uniform type. They can contain floats, integers, complex numbers and strings. They have shape, rank, dimension and size. I believe they are used to perform/calculate operations and to display multi-dimensional data. (2) I noticed that prior to giving data to the ML model, it needed to be manipulated into becoming more equal or 'standard'.

## Day 8 (July 13, 2021)
Today I learned more about the specifics of Neural Networks: weights, biases, functions, different types, etc. I also started developing my first NN model, using a Sarcasm Dataset, but ran into a few errors.

## Day 9 (July 14, 2021)
Today, I continued with yesterday's NN project with the Sarcasm Dataset, and also read through the cheat sheet on CNNs from the self-studying curriculum. It's so exciting to actually see all these concepts and words in an actual machine learning model, and to know that I (somewhat) made it! I can't wait to keep making more projects like these.

## Day 10 (July 15, 2021)
I read through the article the confusion matrixes in ML, and focused on completing the Convolutional Neural Network Tutorial on Kaggle from Day 9. This tutorial was so clear and through, and I defitenly understand more about CNNs now. It was also interesting to see the Confusion matrix analytics and how helpful they can be in real life, because I was a bit confused after reading the article. Finally, I attended a meeting with Crabwalk on how to set realistic goals and how to actually achieve them. It was so exciting to see my goal all planned out, and I can't wait to accomplish it by the end of these six weeks.

## Day 11 (July 16, 2021)
Today, I worked on getting all my Day 10 work done: reading through the presentation on algorithmic bias of AI from Stanford and Google AI, playing Survival of the Best Fit and researching more about how AI impacts human resources and hiring processes.

Reflection Activity: 1. How do you think Machine Learning or AI concepts were utilized in the design of this game? 2. Can you give a real-world example of a biased machine learning model, and share your ideas on how you make this model more fair, inclusive, and equitable? Please reflect on why you selected this specific biased model. (1) While I think there was definitely a lot of prior coding involved, I think it is possible that a real-time Machine Learning Model was given some of my own 'hiring' decisions, along with the data from the company of my choice, as training data. Either way, it explained all of the problem that many hirers face, the reasons why many companies might chose to use an algorithm and the basic processes of creating this ML model. (I actually researched on the GitHub of Survival of the Best Fit, and I believe that there is an actual real-time model going on behind the scenes!!) (2) One example of a biased AI is the rooted racism in the healthcare system. I read an article by 'Towards Data Science' that described how in 2019, an algorithm used to determine the likeliness of a patients needing more medical assistance favored white patients over people of color. The likeliness was mostly rooted in the patient's history of healthcare cost, and for multiple other reasons, black patients tended to have lower healthcare costs than white people. While it was used on millions of people in the US, it was only until later that researchers were able to intervene. I believe that discriminating socio-economic data simply should not have been included as a variable, given how it has historically been used to prohibit people of color from getting basic medical assistance. In the future, researchers and ML developers should be more mindful about the ripples specific data points can create in their models.

## Day 12+13 - Weekend (July 17 + 18, 2021)
Over the Weekend, I caught up on Day 11 work, including reading an article on CNN architecture and the different layers, and completing an introductory dataset practice.

## Day 14 (July 19, 2021)
Today, I worked on developing a CNN for classifying MNIST datasets from Day 11, and uploaded this code onto my GitHub. During our Daily Meeting with our Head Mentors, we learned about CNNs and their structure: a convolution layer, an activation layer, a pooling layer, and a fully connected layer.

Reflection Activity: List the differences between a Convolutional Neural Network and a Fully Connected Neural Network. Discuss layers and their role, and applications of each of the two types of architectures

CNNs:
- made up of convolutional layers, activation layers, pooling layers, flattening layer, and fully connected layers
- not every input connects to every output
- can take in 3D inputs
- used for recognition and classification of images

Fully Connected NNs:
- made up of an input layer, activation layer, and output layer
- each input is connected to each neuron
- must have modification to the input in order to receive images
- used for more generalized purposes of regression and classification

## Day 15 (July 20, 2021)
Today I worked on my Day 14 assignments primarily focused on Loss functions and Model Optimization. For the lesson plan and action items, I read through a bunch of articles and slides and followed a tutorial for making a simple feed-forward neural network model to predict house prices.

## Day 16 (July 21, 2021)
During our Daliy Meeting with the Deep Mentors, we went continued our discussion on ethical AI, and how to make decisions when collecting our datasets, organizing/cleaning data, and creating new models for the benefit of all people. As part of the Self-Curriculum, I worked on Day 15 items including learning more about activation functions from many articles and tutorials, and more specifically how/when to use specific functions. I also began the Day 16 curriculum by reading through an article on what I can actually do for ethical ML.

Reflection Activity: Write a reflection piece on the advantages of the Rectified Linear activation function, along with one use case.

Advantages of ReLU:
- pretty computationally simple + efficient
- capable of outputting a true zero value
- looks/acts like a linear activation function -> easier to optimize bc its behavior is linear or close to linear
- less susceptible to vanishing gradients that prevent deep models from being trained

Uses of ReLU:
ReLU is often used with Multilayer Perceptron (MLP) and Convolutional Neural Networks (CNN) bc it's less susceptible to problems during training, easier to use with lots of data, and doesn't take as much computations.

## Day 17 (July 22, 2021)
Today I worked on the action item for the Day 16 curriculum: creating a Gender Classification ML Model. While I ran into some difficult errors, I resolved them with help from the Head Mentors and almost finished it. I also attended a fantastic talk by Jennifer Chu-Carroll about the Watson Jeopardy machine, what he really 'understands' about his answers and what applications Watson can help us in the present day.

## Day 18 (July 23, 2021)
Today, I finished the Gender Classification model project and uploaded it to my GitHub Page. Additionally, I did the Action Item for Day 17: reviewing image classification techniques with Machine Learning. I am so excited to have finished 3 weeks (aka half of the program) and can't wait for the Create-a-thon!

## Day 19+20 - Weekend (July 24 + 25, 2021)
Over the Weekend, I caught up on Day 17 action item, including completing the Image Classification tutorial and letting it run through its epochs.

## Day 21 (July 26, 2021)
I mostly worked on Day 18's work focused on Overfitting and Regularization. I read through both articles on how to avoid overfitting and what are the common solutions to overfitting, completed the hands on tutorial about different approaches for handling overfitting in deep learning models, and wrote the ethical reflection for how overfitting deep learning models can be â€œdetrimental to society.

Reflection Activity: Can you think of one way that an overfit model can be detrimental?
What is the point of an Artificial Intelligence that isnâ€™t really intelligent? What is the point of a Machine Learning Model that doesnâ€™t learn? Simply put, an overfit model is good on paper, but almost useless in practice. What happens if someone develops an algorithm and says that it is highly accurate, but when put into a real-life situation, it completely fails? Some might not suspect anything because on paper the model looks great, and blindly believe it. Some might realize that somethingâ€™s off, but they might not have the knowledge to articulate their ideas or fix the issue. Some might not even care. In the meantime, the model continues to spew out inaccurate guesses, causing issues left and right. One example is a Computer Vision algorithm that detects facial expressions and predicts emotions. Because the model is overfit, meaning it has memorized its training dataset, it is unable to detect different facial structures, facial expressions, skin tones, etc. It cannot do its job because it cannot understand different faces. Not only is this practically useless, it can also lead to a world of other issues, including discrimination and bias.

## Day 22 (July 27, 2021)
Today I worked on Day 21's lesson plan and action item about Autoencoders and upsampling. This included completing both tutorials, one on adding upscaling layers and the other on building autoencoders with actual code and visualizations. I have uploaded both to GitHub for my future reference. I also watched Professor Rosalid Picard's TEDTalk on the origins of Affective Computing and read about the EMPath 2020 makeathon at Affectiva, both of which were part of Day 22's lesson plan.

## Day 23 (July 28, 2021)
Today I began working on Day 22's action item by reading through the Speech Emotion Analyzer README and setting up the Audio Recorder for my own voice sample.

## Day 24 (July 29, 2021)
Today, I FINALLY was able to complete and upload the Image Classification tutorial about Cats and Dogs. I continued to work on Speech Emotion Analyzer project.

## Day 25 (July 30, 2021)
I completed the Sentiment Analysis Movie Review classifier, applied variations to the model, and committed my code for this NLP model to my GitHub.

Write a reflection piece on the ethical implications of big NLP models such as GPT-2. Some of the ethical implications of big NLP models are that they could misinterpret certain accents or dialects/vernacular languages, such as African-American Vernacular English. Not only would this mean specific words or specific meanings would be ignored or misunderstood, but such bias could make it difficult or even inaccessible for certain groups of people. I know that my own mother, who still has a Russian accent after living in the United States for over 20 years, is sometimes disregarded by our Alexa, while my sister, my father and I are completely understood. This is by no means a detrimental issue, but it shows how ethics especially need to be considered with Natural Language Processing and how NLP could have bigger impacts when brought to a bigger model with a bigger scale.

I also worked on Day 24's self-curriculum, including watching Rana El Kaliouby's TED Talk and starting the tutorial on the emotion detection project using OpenCV.
